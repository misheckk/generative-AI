Roastbot: The Digital Roast Master üé§

Version: v2.1.0 - "The Over-Engineered Insult Generator"

Project Overview

Roastbot is a highly scalable, AI-enhanced microservice that redefines user feedback. Instead of serving bland, generic error codes, this service uses the power of a Large Language Model (LLM) to deliver hyper-personalized, sarcastic, and professional error responses.

Built on the Jac language, the project is inherently scale-agnostic (meaning it's instantly cloud-deployable via jac serve), making it the perfect gateway for handling massive traffic while maintaining peak snark performance.

In short: Your code failed, but our error messages are a work of art.

üõ†Ô∏è Features

    Sassy byLLM Integration: Uses the generate_snarky_response function, powered by a lite Gemini model, to turn technical failures into context-aware, humorous critiques.

    Scale-Agnostic Design: The core logic is encapsulated in the RequestRoaster Walker, allowing the application to be deployed as a high-performance API endpoint with a single command.

    Declarative Structure: Separates the interface (roastbot.jac) from the implementation (roastbot.impl.jac), keeping the architecture clean and maintainable.

    Strict Input Validation: Ensures that any attempt at "Unsanctioned Navigation" (i.e., missing the auth_token) is logged and met with a personalized digital dressing-down.

üöÄ Setup and Installation

Prerequisites

    Python 3.12 (Recommended for Jac stability)

    Jac Language Runtime: Installed via pip.

Steps

    Clone the Repository:
    Bash

git clone https://github.com/misheckk/generative-AI.git
cd generative-AI/interview  # Adjust path to where your files are

Install Jac:
If you're not in your Python 3.12 virtual environment, activate it first, then install Jac:
Bash

pip install jaclang

Set Environment Variable üîë
The project relies on your API key to access the LLM. You must set this variable in your terminal session:
Bash

    # Replace YOUR_KEY_HERE with your actual Gemini API Key
    export GEMINI_API_KEY="YOUR_KEY_HERE"

üíª Execution

The project can be run in two modes: CLI Test Mode (for development) or Server Mode (for deployment).

1. CLI Test Mode (Local Run)

This executes the with entry block defined in roastbot.jac, demonstrating both a successful and a failed request.
Bash

jac run roastbot.jac

Expected Output: You will see the setup messages followed by a personalized, snarky error response generated by the LLM for the failed request, and a simple success message for the second.

2. Server Mode (API Deployment)

To deploy the Roastbot as a live, scale-ready web service (as intended by the Jac framework), use jac serve.
Bash

jac serve roastbot.jac

    This will typically start a server on http://127.0.0.1:8000.

    The RequestRoaster walker is now a callable endpoint that can handle incoming HTTP requests.

üèóÔ∏è Core Code Snippet (The Roaster)

The sassiest part of the application is where it calls the AI function to generate the error message:
Code snippet

impl RequestRoaster.execute {
    if (!self.isValid(self.request_body)) {
        
        # Access the LLM function for the personalized roast
        roast_message = generate_snarky_response(
            error_code=400, 
            endpoint=self.requested_endpoint,
            attempted_data=self.request_body
        );
        
        print("\n--- RESPONSE: HTTP 400 Bad Request ---");
        print(roast_message);
        
        disengage; 
    }
    # ... Success Path ...
}
